{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2642bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usunąć # przy pobieraniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2fea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a5ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unnecesary column and chech length of messeage\n",
    "normal = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "normal.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "normal.columns = ['label', 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925e8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4de960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of message\n",
    "normal['char_count'] = normal['content'].apply(len)\n",
    "#Counting words\n",
    "normal['word_count'] = normal['content'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad966472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of average word in message\n",
    "def avg_word_len(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "normal['avg_word_len'] = normal['content'].apply(lambda x: avg_word_len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7ecbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting stopwords\n",
    "#nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "normal['stopwords_count'] = normal['content'].apply(lambda x : len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcc6d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>specials_count</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>uppers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "      <td>32</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "      <td>26</td>\n",
       "      <td>5.192308</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "      <td>26</td>\n",
       "      <td>5.115385</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "      <td>29</td>\n",
       "      <td>4.344828</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content  char_count  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...         111   \n",
       "1   ham                      Ok lar... Joking wif u oni...          29   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...         155   \n",
       "3   ham  U dun say so early hor... U c already then say...          49   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          61   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...         148   \n",
       "6   ham  Even my brother is not like to speak with me. ...          77   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...         160   \n",
       "8  spam  WINNER!! As a valued network customer you have...         158   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...         154   \n",
       "\n",
       "   word_count  avg_word_len  stopwords_count  specials_count  numerics_count  \\\n",
       "0          20      4.600000                4              28               0   \n",
       "1           6      4.000000                0              11               0   \n",
       "2          28      4.571429                5              33               2   \n",
       "3          11      3.545455                2              16               0   \n",
       "4          13      3.769231                5              14               0   \n",
       "5          32      3.656250               13              40               1   \n",
       "6          16      3.875000                6              17               0   \n",
       "7          26      5.192308                9              31               0   \n",
       "8          26      5.115385                5              32               1   \n",
       "9          29      4.344828                8              30               2   \n",
       "\n",
       "   uppers_count  \n",
       "0             0  \n",
       "1             0  \n",
       "2             2  \n",
       "3             2  \n",
       "4             1  \n",
       "5             0  \n",
       "6             0  \n",
       "7             0  \n",
       "8             2  \n",
       "9             3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting specials and  numeric chars\n",
    "normal['specials_count'] = normal['content'].apply(lambda x: len(re.sub('[\\w]+', '', x)))\n",
    "normal['numerics_count'] = normal['content'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "#Counting words with only upper letters\n",
    "normal['uppers_count'] = normal['content'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "normal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c5a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tu zrobić wykresy wstepne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d1205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea9b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5b82003daf36>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  normal['content'] = normal['content'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "#save date before processing to comparize\n",
    "normal['backup'] = normal['content']\n",
    "\n",
    "#toLower\n",
    "normal['content'] = normal['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#remove specials\n",
    "normal['content'] = normal['content'].str.replace('[^\\w\\s]','')\n",
    "#remove stopwords\n",
    "normal['content'] = normal['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad1fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u       1119\n",
       "call     576\n",
       "2        478\n",
       "im       462\n",
       "get      386\n",
       "ur       384\n",
       "4        287\n",
       "dont     279\n",
       "go       278\n",
       "ok       277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove often used words\n",
    "freq = pd.Series(' '.join(normal['content']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b14005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jurong point crazy available bugis n great wor...\n",
       "1                                   lar joking wif oni\n",
       "2    free entry wkly comp win fa cup final tkts 21s...\n",
       "3                      dun say early hor c already say\n",
       "4               nah think goes usf lives around though\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "normal['content'] = normal['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "normal['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efde490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funs               1\n",
       "internetservice    1\n",
       "janinexx           1\n",
       "officethenampet    1\n",
       "hvae               1\n",
       "virtual            1\n",
       "09050001295        1\n",
       "corrct             1\n",
       "arises             1\n",
       "categories         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove rarely used words\n",
    "freq = pd.Series(' '.join(normal['content']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f705c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jurong point crazy available bugis n great wor...\n",
       "1                                   lar joking wif oni\n",
       "2    free entry wkly comp win fa cup final tkts 21s...\n",
       "3                      dun say early hor c already say\n",
       "4               nah think goes usf lives around though\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "normal['content'] = normal['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "normal['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b3c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair messages\n",
    "#normal['content'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7038aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "#st = PorterStemmer()\n",
    "#normal['content'] = normal['content'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc1c8c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['lar', 'joking', 'wif', 'oni'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "#nltk.download('punkt')\n",
    "TextBlob(normal['content'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c2ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatisation\n",
    "#nltk.download('wordnet')\n",
    "normal['content'] = normal['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b8ab8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>backup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lar joking wif oni</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win fa cup final tkts 21s...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dun say early hor c already say</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah think go usf life around though</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freemsg hey darling 3 week word back id like f...</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobile 11 month r entitled update latest colou...</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gonna home soon want talk stuff anymore tonigh...</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>six chance win cash 100 20000 pound txt csh11 ...</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>urgent 1 week free membership å100000 prize ja...</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ive searching right word thank breather promis...</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>date sunday</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xxxmobilemovieclub use credit click wap link n...</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oh kim watching</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eh remember spell name yes v naughty make v wet</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fine thatåõs way feel thatåõs way gota b</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>england v macedonia miss goalsteam news txt na...</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>seriously spell name</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iûm going try month ha ha joking</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ì_ pay first lar da stock comin</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aft finish lunch str lor ard 3 smth lor finish...</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>forced eat slice really hungry tho suck mark g...</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lol always convincing</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>catch bus frying egg make tea eating mom left ...</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>back amp packing car ill let know there room</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ahhh work vaguely remember feel like lol</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>wait thats still clear sure sarcastic thats x ...</td>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>yeah got v apologetic n fallen actin like spoi...</td>\n",
       "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>k tell anything</td>\n",
       "      <td>K tell me anything about you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fear fainting housework quick cuppa</td>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>thanks subscription ringtone uk mobile charged...</td>\n",
       "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>yup home look timing msg ì_ xuhui going learn ...</td>\n",
       "      <td>Yup... Ok i go home look at the timings then i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>oops ill let know roommate done</td>\n",
       "      <td>Oops, I'll let you know when my roommate's done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>see letter b car</td>\n",
       "      <td>I see the letter B on my car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>anything lor decide</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hello hows saturday texting see youd decided a...</td>\n",
       "      <td>Hello! How's you and how did saturday go? I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pls ahead watt wanted sure great weekend abiola</td>\n",
       "      <td>Pls go ahead with watts. I just wanted to be s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>forget tell want need crave love sweet arabian...</td>\n",
       "      <td>Did I forget to tell you ? I want you , I need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>07732584351 rodger burn msg tried reply sm fre...</td>\n",
       "      <td>07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>seeing</td>\n",
       "      <td>WHO ARE YOU SEEING?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>great hope like man well endowed ltgt inch</td>\n",
       "      <td>Great! I hope you like your man well endowed. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>callsmessagesmissed call</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>didnt hep b immunisation nigeria</td>\n",
       "      <td>Didn't you get hep b immunisation in nigeria.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fair enough anything going</td>\n",
       "      <td>Fair enough, anything going on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>yeah hopefully tyler cant could maybe ask arou...</td>\n",
       "      <td>Yeah hopefully, if tyler can't do it I could m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>know stubborn didnt even want hospital kept te...</td>\n",
       "      <td>U don't know how stubborn I am. I didn't even ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0   jurong point crazy available bugis n great wor...   \n",
       "1                                  lar joking wif oni   \n",
       "2   free entry wkly comp win fa cup final tkts 21s...   \n",
       "3                     dun say early hor c already say   \n",
       "4                 nah think go usf life around though   \n",
       "5   freemsg hey darling 3 week word back id like f...   \n",
       "6       even brother like speak treat like aid patent   \n",
       "7   per request melle melle oru minnaminunginte nu...   \n",
       "8   winner valued network customer selected receiv...   \n",
       "9   mobile 11 month r entitled update latest colou...   \n",
       "10  gonna home soon want talk stuff anymore tonigh...   \n",
       "11  six chance win cash 100 20000 pound txt csh11 ...   \n",
       "12  urgent 1 week free membership å100000 prize ja...   \n",
       "13  ive searching right word thank breather promis...   \n",
       "14                                        date sunday   \n",
       "15  xxxmobilemovieclub use credit click wap link n...   \n",
       "16                                    oh kim watching   \n",
       "17    eh remember spell name yes v naughty make v wet   \n",
       "18           fine thatåõs way feel thatåõs way gota b   \n",
       "19  england v macedonia miss goalsteam news txt na...   \n",
       "20                               seriously spell name   \n",
       "21                   iûm going try month ha ha joking   \n",
       "22                    ì_ pay first lar da stock comin   \n",
       "23  aft finish lunch str lor ard 3 smth lor finish...   \n",
       "24                 ffffffffff alright way meet sooner   \n",
       "25  forced eat slice really hungry tho suck mark g...   \n",
       "26                              lol always convincing   \n",
       "27  catch bus frying egg make tea eating mom left ...   \n",
       "28       back amp packing car ill let know there room   \n",
       "29           ahhh work vaguely remember feel like lol   \n",
       "30  wait thats still clear sure sarcastic thats x ...   \n",
       "31  yeah got v apologetic n fallen actin like spoi...   \n",
       "32                                    k tell anything   \n",
       "33                fear fainting housework quick cuppa   \n",
       "34  thanks subscription ringtone uk mobile charged...   \n",
       "35  yup home look timing msg ì_ xuhui going learn ...   \n",
       "36                    oops ill let know roommate done   \n",
       "37                                   see letter b car   \n",
       "38                                anything lor decide   \n",
       "39  hello hows saturday texting see youd decided a...   \n",
       "40    pls ahead watt wanted sure great weekend abiola   \n",
       "41  forget tell want need crave love sweet arabian...   \n",
       "42  07732584351 rodger burn msg tried reply sm fre...   \n",
       "43                                             seeing   \n",
       "44         great hope like man well endowed ltgt inch   \n",
       "45                           callsmessagesmissed call   \n",
       "46                   didnt hep b immunisation nigeria   \n",
       "47                         fair enough anything going   \n",
       "48  yeah hopefully tyler cant could maybe ask arou...   \n",
       "49  know stubborn didnt even want hospital kept te...   \n",
       "\n",
       "                                               backup  \n",
       "0   Go until jurong point, crazy.. Available only ...  \n",
       "1                       Ok lar... Joking wif u oni...  \n",
       "2   Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3   U dun say so early hor... U c already then say...  \n",
       "4   Nah I don't think he goes to usf, he lives aro...  \n",
       "5   FreeMsg Hey there darling it's been 3 week's n...  \n",
       "6   Even my brother is not like to speak with me. ...  \n",
       "7   As per your request 'Melle Melle (Oru Minnamin...  \n",
       "8   WINNER!! As a valued network customer you have...  \n",
       "9   Had your mobile 11 months or more? U R entitle...  \n",
       "10  I'm gonna be home soon and i don't want to tal...  \n",
       "11  SIX chances to win CASH! From 100 to 20,000 po...  \n",
       "12  URGENT! You have won a 1 week FREE membership ...  \n",
       "13  I've been searching for the right words to tha...  \n",
       "14                I HAVE A DATE ON SUNDAY WITH WILL!!  \n",
       "15  XXXMobileMovieClub: To use your credit, click ...  \n",
       "16                         Oh k...i'm watching here:)  \n",
       "17  Eh u remember how 2 spell his name... Yes i di...  \n",
       "18  Fine if thatåÕs the way u feel. ThatåÕs the wa...  \n",
       "19  England v Macedonia - dont miss the goals/team...  \n",
       "20          Is that seriously how you spell his name?  \n",
       "21  IÛ÷m going to try for 2 months ha ha only joking  \n",
       "22  So Ì_ pay first lar... Then when is da stock c...  \n",
       "23  Aft i finish my lunch then i go str down lor. ...  \n",
       "24  Ffffffffff. Alright no way I can meet up with ...  \n",
       "25  Just forced myself to eat a slice. I'm really ...  \n",
       "26                     Lol your always so convincing.  \n",
       "27  Did you catch the bus ? Are you frying an egg ...  \n",
       "28  I'm back &amp; we're packing the car now, I'll...  \n",
       "29  Ahhh. Work. I vaguely remember that! What does...  \n",
       "30  Wait that's still not all that clear, were you...  \n",
       "31  Yeah he got in at 2 and was v apologetic. n ha...  \n",
       "32                      K tell me anything about you.  \n",
       "33  For fear of fainting with the of all that hous...  \n",
       "34  Thanks for your subscription to Ringtone UK yo...  \n",
       "35  Yup... Ok i go home look at the timings then i...  \n",
       "36    Oops, I'll let you know when my roommate's done  \n",
       "37                       I see the letter B on my car  \n",
       "38                        Anything lor... U decide...  \n",
       "39  Hello! How's you and how did saturday go? I wa...  \n",
       "40  Pls go ahead with watts. I just wanted to be s...  \n",
       "41  Did I forget to tell you ? I want you , I need...  \n",
       "42  07732584351 - Rodger Burns - MSG = We tried to...  \n",
       "43                                WHO ARE YOU SEEING?  \n",
       "44  Great! I hope you like your man well endowed. ...  \n",
       "45                   No calls..messages..missed calls  \n",
       "46      Didn't you get hep b immunisation in nigeria.  \n",
       "47                    Fair enough, anything going on?  \n",
       "48  Yeah hopefully, if tyler can't do it I could m...  \n",
       "49  U don't know how stubborn I am. I didn't even ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal[['content', 'backup']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3869a356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>lar joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0   ham  jurong point crazy available bugis n great wor...\n",
       "1   ham                                 lar joking wif oni\n",
       "2  spam  free entry wkly comp win fa cup final tkts 21s...\n",
       "3   ham                    dun say early hor c already say\n",
       "4   ham                nah think go usf life around though"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorisation\n",
    "toSave = normal\n",
    "\n",
    "toSave.drop(['backup', 'char_count', 'word_count', 'avg_word_len', 'stopwords_count', 'specials_count', 'numerics_count', 'uppers_count'], axis=1, inplace=True)\n",
    "\n",
    "toSave.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f789719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-c981204e43a3>:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input, word2vec_output)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'point'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c981204e43a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mglove_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'spam_clean.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword2vec_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'spam_clean.csv.word2vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 )\n\u001b[1;32m-> 1519\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py\u001b[0m in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mglovekv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mnum_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglovekv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglovekv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m         \"\"\"\n\u001b[1;32m-> 1630\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1631\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1896\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no_header only available for text-format files\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m                 \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_word2vec_detect_sizes_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m             \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m             \u001b[0mfin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_detect_sizes_text\u001b[1;34m(fin, limit, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1835\u001b[0m             \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# don't bother parsing lines past the 1st\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1836\u001b[1;33m         \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1837\u001b[0m         \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_line_to_vector\u001b[1;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m     \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m     \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'point'"
     ]
    }
   ],
   "source": [
    "toSave.to_csv('spam_clean.csv', index = False)\n",
    "\n",
    "glove_input = ('spam_clean.csv')\n",
    "word2vec_output = ('spam_clean.csv.word2vec')\n",
    "glove2word2vec(glove_input, word2vec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a58a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
